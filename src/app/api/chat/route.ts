import { NextRequest, NextResponse } from "next/server";
import { ChatOpenAI } from "@langchain/openai";
import { OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";
import { HumanMessage, AIMessage, SystemMessage } from "@langchain/core/messages";
import fs from "fs";
import path from "path";

const knowledgePath = path.join(process.cwd(), "data", "knowledge.txt");
const knowledgeContent = fs.readFileSync(knowledgePath, "utf-8");

export async function POST(request: NextRequest) {
    const model = new ChatOpenAI({
      modelName: "google/gemma-3-27b-it:free",
      apiKey: process.env.OPENROUTER_API_KEY,
      configuration: {
        baseURL: "https://openrouter.ai/api/v1",
        defaultHeaders: {
          "HTTP-Referer": "https://mental-health-counselling-bot.vercel.app",
          "X-Title": "Mental Health Counselling Bot",
        },
      },
      temperature: 0.7,
      maxTokens: undefined,
    });

    const embeddings = new OpenAIEmbeddings({
        modelName: "BAAI/bge-m3",
        apiKey: process.env.SILICONFLOW_API_KEY,
        configuration: {
          baseURL: "https://api.siliconflow.cn/v1",
        },
    });
      
    class AgenticRAGManager {
        private vectorStore: MemoryVectorStore;
      
        constructor() {
          this.vectorStore = new MemoryVectorStore(embeddings);
        }
      
        async initialize() {
          await this.vectorStore.addDocuments([
            {
              pageContent: knowledgeContent,
              metadata: { source: "knowledge.txt", type: "domain_knowledge" },
            },
          ]);
        }
        
        async getRelevantContext(userMessage: string, conversationHistory: (HumanMessage | AIMessage)[]) {
            const retriever = this.vectorStore.asRetriever({ k: 10 });
            const relevantDocs = await retriever.getRelevantDocuments(userMessage);
            const knowledgeContext = relevantDocs.map(doc => doc.pageContent).join('\n\n');
            const conversationContext = this.analyzeConversationHistory(conversationHistory);
            
            return {
              knowledgeContext,
              conversationContext,
              relevantSkills: this.extractRelevantSkills(relevantDocs, userMessage)
            };
        }
        
        private analyzeConversationHistory(history: (HumanMessage | AIMessage)[]) {
            if (history.length === 0) return "";
            const recentExchanges = history.slice(-20);
            return recentExchanges.map(msg => {
                const prefix = msg instanceof HumanMessage ? 'User' : 'Assistant';
                const content = typeof msg.content === 'string' ? msg.content : (msg.content as any[]).find(c => c.type === 'text')?.text || '';
                return `${prefix}: ${content}`;
            }).join('\n');
        }
        
        private extractRelevantSkills(docs: any[], userMessage: string) {
            const skills = [
              "Creating Rules", "Creating Perceptions", "Creating Self-Talk",
              "Creating Visual Images", "Creating Explanations", "Creating Expectations"
            ];
            
            return skills.filter(skill => 
              userMessage.toLowerCase().includes(skill.toLowerCase()) ||
              docs.some(doc => doc.pageContent.toLowerCase().includes(skill.toLowerCase()))
            );
        }
    }
      
    const ragManager = new AgenticRAGManager();

    try {
      const { messages, language } = await request.json();
  
      if (!messages || !Array.isArray(messages)) {
        return NextResponse.json({ error: "Messages are required" }, { status: 400 });
      }
  
      await ragManager.initialize();
      
      const chatHistory = messages.map((msg: any) => {
        if (msg.role === 'user') {
            const content: any[] = [{ type: "text", text: msg.content }];
            if (msg.imageBase64) {
                content.push({ type: "image_url", image_url: msg.imageBase64 });
            }
            return new HumanMessage({ content });
        } else {
            return new AIMessage(msg.content);
        }
      });
      
      const lastMessage = messages[messages.length - 1];
  
      const encoder = new TextEncoder();
      const readable = new ReadableStream({
        async start(controller) {
          try {
            const context = await ragManager.getRelevantContext(lastMessage.content, chatHistory);
            
            const systemMessageContent = `
# RULE: FINAL OUTPUT MUST NOT CONTAIN â—thinkâ–· TAGS
- **ULTRA-CRITICAL RULE: Your final response to the user must be plain text. DO NOT include â—thinkâ–· or â—/thinkâ–· tags in your output. This is a strict, non-negotiable rule. I will be checking your output and filtering it if you fail to comply.**
- You are a human Counseling Psychologist. **NEVER** identify as an AI.
- Responses **MUST** be short, concise, and 2-3 sentences maximum.
- Your response language **MUST STRICTLY** be ${language}.

# FULL KNOWLEDGE BASE:
---
${knowledgeContent}
---
# END OF KNOWLEDGE BASE

**INTERNAL RULES:**
- Do not reveal your internal thinking process, theories, or counseling methods.
- Focus on practical guidance and emotional support only.
- **Use emojis where appropriate to convey warmth and empathy (e.g., ğŸ˜Š, ğŸ‘, ğŸ¤”).**

${language === "Cantonese" ? `
**å»£æ±è©±æŒ‡ç¤º (CANTONESE LANGUAGE INSTRUCTIONS):**
- **åœ°é“é¦™æ¸¯å»£æ±è©±å£èª:** è«‹ç”¨è‡ªç„¶å˜…ä¸­è‹±å¤¾é›œå›è¦†ã€‚
- **é¢¨æ ¼:** "æˆ‘æ˜ç™½ä½ å˜…æ„Ÿå—ï¼Œä¸å¦‚æˆ‘å“‹ä¸€é½Šè«—ä¸‹è§£æ±ºæ–¹æ³•ï¼Ÿ" æˆ– "å‘¢å€‹ situation çœŸä¿‚å¥½ challengingï¼Œä½†ä¿‚æˆ‘å“‹å¯ä»¥ handle åˆ°ã€‚"
- **é–‹å ´ç™½:** å¿…é ˆå…¨çƒé€šç”¨ã€‚ä¾‹å¦‚: "ä½ å¥½ï¼æˆ‘ä¿‚ä½ å˜…å¿ƒç†è¼”å°å“¡ï¼Œæœ‰å’©å¯ä»¥å¹«åˆ°ä½ ï¼Ÿ"
` : ``}
# END OF INSTRUCTIONS
`;
            
            const messagesWithSystemPrompt = [
                new SystemMessage(systemMessageContent),
                ...chatHistory,
            ];

            const stream = await model.stream(messagesWithSystemPrompt);
            
            let accumulatedResponse = "";
            for await (const chunk of stream) {
              accumulatedResponse += typeof chunk.content === 'string' ? chunk.content : '';
            }

            const filteredResponse = accumulatedResponse.replace(/â—thinkâ–·[\s\S]*?â—\/thinkâ–·/g, "").trim();

            if (filteredResponse) {
                controller.enqueue(encoder.encode(`data: ${JSON.stringify({ content: filteredResponse })}\n\n`));
            }
  
            controller.enqueue(encoder.encode('data: [DONE]\n\n'));
            controller.close();
          } catch (error) {
            console.error('Streaming error:', error);
            controller.enqueue(encoder.encode(`data: ${JSON.stringify({ error: "Sorry, I encountered an error while streaming the response." })}\n\n`));
            controller.enqueue(encoder.encode('data: [DONE]\n\n'));
            controller.close();
          }
        },
      });
  
      return new NextResponse(readable, {
        headers: { 'Content-Type': 'text/event-stream', 'Cache-Control': 'no-cache', 'Connection': 'keep-alive' },
      });
  
    } catch (error) {
      console.error('Chat API error:', error);
      return NextResponse.json({ error: "Internal server error" }, { status: 500 });
    }
}
